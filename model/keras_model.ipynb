{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 images belonging to 3 classes.\n",
      "Found 6 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = (256,256, 3)\n",
    "batch_size = 8\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../resized_data/train',  # this is the target directory\n",
    "        #target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '../resized_data/valid',\n",
    "        #target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=image_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 2 steps, validate for 1 steps\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 675ms/step - loss: 0.9722 - accuracy: 0.5000 - val_loss: 1.1111 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 1s 335ms/step - loss: 0.9722 - accuracy: 0.5000 - val_loss: 1.1111 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 1s 341ms/step - loss: 0.9722 - accuracy: 0.1667 - val_loss: 1.1111 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 0.9722 - accuracy: 0.5833 - val_loss: 1.1111 - val_accuracy: 0.8333\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.9722 - accuracy: 0.5833 - val_loss: 1.1111 - val_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 1s 343ms/step - loss: 0.9722 - accuracy: 0.5833 - val_loss: 1.1111 - val_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 1s 342ms/step - loss: 0.9722 - accuracy: 0.6667 - val_loss: 1.1111 - val_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 0.9722 - accuracy: 0.7500 - val_loss: 1.1111 - val_accuracy: 0.1667\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 1s 344ms/step - loss: 0.9722 - accuracy: 0.7500 - val_loss: 1.1111 - val_accuracy: 0.3333\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.9722 - accuracy: 0.7500 - val_loss: 1.1111 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 1s 347ms/step - loss: 0.9722 - accuracy: 1.0000 - val_loss: 1.1111 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 0.9722 - accuracy: 0.9167 - val_loss: 1.1111 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 1s 347ms/step - loss: 0.9722 - accuracy: 0.3333 - val_loss: 1.1111 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 0.9722 - accuracy: 0.0000e+00 - val_loss: 1.1111 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 1s 347ms/step - loss: 0.9722 - accuracy: 0.0000e+00 - val_loss: 1.1111 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.9722 - accuracy: 0.0000e+00 - val_loss: 1.1111 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 0.9722 - accuracy: 1.0000 - val_loss: 1.1111 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 1s 339ms/step - loss: 0.9722 - accuracy: 1.0000 - val_loss: 1.1111 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.9722 - accuracy: 1.0000 - val_loss: 1.1111 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 1s 342ms/step - loss: 0.9722 - accuracy: 0.0000e+00 - val_loss: 1.1111 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc1f3bec88>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        #steps_per_epoch=2000//12,\n",
    "        epochs=20,\n",
    "        validation_data=validation_generator)\n",
    "        #validation_steps=1000//6)\n",
    "#model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
